## ðŸŽ¸ Automatic Guitar Chord Transcription

This project implements and compares two approaches for automatic guitar chord transcription from audio:

A classical signal-processing baseline, using HPSS, chroma extraction, template matching, and smoothing.

A deep-learning model (in development), based on CNN/CRNN architectures trained on spectrogram features.

The system is evaluated on the Isophonics Beatles dataset, using frame-level accuracy and chord timelines for qualitative inspection.

## ðŸš€ Installation

python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

Make sure you have ffmpeg installed if using librosa on audio files.

## ðŸ“‚ Project Structure

chord-transcription/
â”‚
â”œâ”€â”€ report/
â”‚ â””â”€â”€ intermediate/ # Intermediate report (PDF)
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ audio/ # Audio files (e.g., Let It Be, I'll Follow the Sun)
â”‚ â”œâ”€â”€ annotations/ # .lab ground-truth labels from Isophonics
â”‚ â””â”€â”€ features/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ classical/ # Classical baseline implementation
â”‚ â”‚ â”œâ”€â”€ preprocessing.py
â”‚ â”‚ â”œâ”€â”€ chord_templates.py
â”‚ â”‚ â”œâ”€â”€ template_matching.py
â”‚ â”‚ â”œâ”€â”€ smoothing.py
â”‚ â”‚ â””â”€â”€ evaluation.py
â”‚ â”‚
â”‚ â”œâ”€â”€ utils/ # Helpers (I/O, plotting, etc.)
â”‚ â””â”€â”€ deep/ # Deep learning model (upcoming)
â”‚
â””â”€â”€ scripts/
â”œâ”€â”€ run_preprocessing.py
â”œâ”€â”€ run_classical.py # Main script for classical pipeline
â””â”€â”€ run_deep.py # Will be added later

## ðŸŽ¼ Running the Classical Baseline

Run the full classical chord-recognition pipeline:

python scripts/run_classical.py

This script performs:

audio loading and HPSS

chroma CQT extraction

template matching

smoothing and segmentation

evaluation against ground truth

Output includes:

predicted chord timeline

framewise accuracy

visual figures (waveform, chroma, classical timeline)

## ðŸŽ§ Dataset

This project uses the Isophonics Beatles annotations, containing:

.wav audio files

.lab chord ground-truth files

Download from:
https://isophonics.net/content/reference-annotations-beatles

Place them in:

data/audio/
data/annotations/

## ðŸ§  Deep Learning (Upcoming)

The deep-learning system will follow a CNN/CRNN architecture trained on spectrograms derived from the same dataset.
A new script run_deep.py and training utilities will be added during the next phase of the project.

## ðŸ“Š Results (Classical Baseline)

Song Accuracy
Let It Be 69.97%
I'll Follow the Sun 20.52%

These results reflect the well-known behavior of template-matching systems: high performance on simple diatonic progressions, lower performance on harmonically complex material.

## ðŸ“Œ Next Steps

Implement deep-learning chord recognition model (CNN/CRNN).

Evaluate and compare with the classical baseline.

Extend the report with quantitative and qualitative analyses.
